{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6+U1X8T9l6bT6de9bCbmc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gopi376/ICP2_Asignment02/blob/main/Assignment_ICP_Keras_700759819.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zem3y26Rzu9k",
        "outputId": "17039562-29f7-4516-c602-c6354db8a88f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/gdrive/My Drive/diabetes.csv'\n"
      ],
      "metadata": {
        "id": "GsfibW95z29Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "# load dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(path_to_csv, header=None).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "np.random.seed(155)\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,\n",
        "                                     initial_epoch=0)\n",
        "print(my_first_nn.summary())\n",
        "print(my_first_nn.evaluate(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KgbvKPyz76a",
        "outputId": "82753f0d-c06f-4275-e460-612c9082abbe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 2ms/step - loss: 12.8154 - acc: 0.3385\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 5.1904 - acc: 0.4340\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.9049 - acc: 0.6441\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.5431 - acc: 0.6858\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.2958 - acc: 0.6736\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.2043 - acc: 0.6649\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.1242 - acc: 0.6632\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.0588 - acc: 0.6597\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.0009 - acc: 0.6597\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.9522 - acc: 0.6493\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.9104 - acc: 0.6545\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8787 - acc: 0.6580\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8497 - acc: 0.6493\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8309 - acc: 0.6580\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8041 - acc: 0.6615\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7927 - acc: 0.6632\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7737 - acc: 0.6788\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7639 - acc: 0.6788\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7646 - acc: 0.6597\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7606 - acc: 0.6736\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7234 - acc: 0.6806\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7225 - acc: 0.6736\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7170 - acc: 0.6719\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7111 - acc: 0.6788\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7098 - acc: 0.6719\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6956 - acc: 0.6875\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6946 - acc: 0.6823\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.6892\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6860 - acc: 0.6771\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6733 - acc: 0.6875\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6694 - acc: 0.6858\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6760 - acc: 0.6806\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6675 - acc: 0.7049\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6644 - acc: 0.6997\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6536 - acc: 0.6927\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6541 - acc: 0.6840\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6488 - acc: 0.7049\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6663 - acc: 0.7031\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6511 - acc: 0.6944\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6429 - acc: 0.7049\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6618 - acc: 0.6892\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6442 - acc: 0.7118\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6436 - acc: 0.6997\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6306 - acc: 0.6875\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6330 - acc: 0.7257\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6304 - acc: 0.6944\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6419 - acc: 0.7066\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6389 - acc: 0.7153\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6165 - acc: 0.7188\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6115 - acc: 0.7135\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6128 - acc: 0.7170\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6209 - acc: 0.7188\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6190 - acc: 0.7309\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6097 - acc: 0.7101\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6102 - acc: 0.7153\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6107 - acc: 0.7222\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6054 - acc: 0.7170\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6027 - acc: 0.7153\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6015 - acc: 0.7066\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6126 - acc: 0.7222\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5953 - acc: 0.7292\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6032 - acc: 0.7118\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5990 - acc: 0.7118\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6133 - acc: 0.7049\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6402 - acc: 0.6910\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5906 - acc: 0.7205\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5934 - acc: 0.7326\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5935 - acc: 0.7274\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6212 - acc: 0.6944\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5879 - acc: 0.7135\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6046 - acc: 0.7135\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5788 - acc: 0.7205\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6084 - acc: 0.7257\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5877 - acc: 0.7101\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5948 - acc: 0.7257\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5919 - acc: 0.7170\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5928 - acc: 0.7170\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5870 - acc: 0.7309\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5747 - acc: 0.7274\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5706 - acc: 0.7326\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5757 - acc: 0.7205\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5787 - acc: 0.7326\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5705 - acc: 0.7153\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5849 - acc: 0.7205\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5735 - acc: 0.7274\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5797 - acc: 0.7153\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5703 - acc: 0.7274\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5683 - acc: 0.7448\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5682 - acc: 0.7396\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5692 - acc: 0.7344\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5617 - acc: 0.7326\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5652 - acc: 0.7205\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5674 - acc: 0.7170\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5683 - acc: 0.7326\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5643 - acc: 0.7309\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5579 - acc: 0.7326\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5683 - acc: 0.7188\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5651 - acc: 0.7240\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5948 - acc: 0.7101\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5842 - acc: 0.7292\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 20)                180       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201 (804.00 Byte)\n",
            "Trainable params: 201 (804.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6652 - acc: 0.6510\n",
            "[0.6652278900146484, 0.6510416865348816]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.a Add more Dense layers to the existing code and check how the accuracy changes.\n"
      ],
      "metadata": {
        "id": "7R2ZW2sb0GA_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer with input\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n",
        "print(my_first_nn.summary()) #Summary\n",
        "print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhjK8-dA0HQZ",
        "outputId": "418d6697-2868-47a5-e292-9e4af3506c9a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 20)                180       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2301 (8.99 KB)\n",
            "Trainable params: 2301 (8.99 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.5600 - acc: 0.6979\n",
            "[0.5600417852401733, 0.6979166865348816]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.b. Changed the data source to Breast Cancer dataset available in the source code folder and make required changes. Report accuracy of the model.\n"
      ],
      "metadata": {
        "id": "tVVZ6Nju0NKQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/gdrive/My Drive/breastcancer.csv'"
      ],
      "metadata": {
        "id": "QqY0xxUu6NBN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load dataset\n",
        "cancer_data = load_breast_cancer()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(cancer_data.data, cancer_data.target,\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "np.random.seed(155)\n",
        "my_nn = Sequential() # create model\n",
        "my_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer 1\n",
        "my_first_nn.add(Dense(16, activation='relu'))\n",
        "my_first_nn.add(Dense(12, activation='relu'))\n",
        "my_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_nn_fitted = my_nn.fit(X_train, Y_train, epochs=100,\n",
        "                         initial_epoch=0)\n",
        "print(my_nn.summary())\n",
        "print(my_nn.evaluate(X_test,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0zCad_S0OXE",
        "outputId": "d15ffbdb-172b-4f87-d3ab-6dbeb1868bfc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 2.2847 - acc: 0.7441\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.7878 - acc: 0.8568\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.5265 - acc: 0.9061\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4820 - acc: 0.8991\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4786 - acc: 0.9038\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4310 - acc: 0.9061\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3891 - acc: 0.9038\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3603 - acc: 0.8991\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3421 - acc: 0.9085\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3391 - acc: 0.9014\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3170 - acc: 0.9131\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2920 - acc: 0.9155\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3092 - acc: 0.9131\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2853 - acc: 0.9131\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2892 - acc: 0.9131\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2681 - acc: 0.9108\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3043 - acc: 0.9202\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2663 - acc: 0.9155\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2903 - acc: 0.9225\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2396 - acc: 0.9202\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2572 - acc: 0.9225\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2318 - acc: 0.9202\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2160 - acc: 0.9343\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2290 - acc: 0.9249\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2220 - acc: 0.9131\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1962 - acc: 0.9296\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2146 - acc: 0.9343\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2124 - acc: 0.9343\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2037 - acc: 0.9272\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2377 - acc: 0.9343\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2136 - acc: 0.9249\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2196 - acc: 0.9272\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2008 - acc: 0.9366\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2777 - acc: 0.9178\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2083 - acc: 0.9178\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2254 - acc: 0.9131\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1994 - acc: 0.9225\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2167 - acc: 0.9413\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1943 - acc: 0.9272\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1864 - acc: 0.9249\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1621 - acc: 0.9460\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2122 - acc: 0.9343\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2206 - acc: 0.9296\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1826 - acc: 0.9249\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2416 - acc: 0.9343\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1953 - acc: 0.9343\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2272 - acc: 0.9249\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1813 - acc: 0.9343\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1876 - acc: 0.9296\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1748 - acc: 0.9390\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1664 - acc: 0.9343\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1866 - acc: 0.9366\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2575 - acc: 0.9108\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2003 - acc: 0.9343\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1558 - acc: 0.9390\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1543 - acc: 0.9296\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1522 - acc: 0.9437\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1621 - acc: 0.9319\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1732 - acc: 0.9225\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1838 - acc: 0.9343\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1485 - acc: 0.9437\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1582 - acc: 0.9272\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1769 - acc: 0.9319\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2776 - acc: 0.9085\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1944 - acc: 0.9460\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1754 - acc: 0.9413\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1676 - acc: 0.9413\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1694 - acc: 0.9319\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1492 - acc: 0.9343\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1484 - acc: 0.9460\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1391 - acc: 0.9437\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1544 - acc: 0.9366\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1433 - acc: 0.9413\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1637 - acc: 0.9343\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1873 - acc: 0.9225\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1784 - acc: 0.9390\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1469 - acc: 0.9343\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1552 - acc: 0.9460\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2436 - acc: 0.9202\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1661 - acc: 0.9390\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1985 - acc: 0.9366\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1471 - acc: 0.9366\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2506 - acc: 0.9155\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1484 - acc: 0.9437\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1538 - acc: 0.9484\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1421 - acc: 0.9390\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1436 - acc: 0.9366\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1666 - acc: 0.9296\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2005 - acc: 0.9343\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2879 - acc: 0.9061\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2561 - acc: 0.9225\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1871 - acc: 0.9366\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1693 - acc: 0.9390\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1748 - acc: 0.9413\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1606 - acc: 0.9460\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1379 - acc: 0.9366\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1570 - acc: 0.9413\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1603 - acc: 0.9413\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1411 - acc: 0.9460\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1290 - acc: 0.9460\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 641 (2.50 KB)\n",
            "Trainable params: 641 (2.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2298 - acc: 0.9371\n",
            "[0.22979402542114258, 0.9370629191398621]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Normalize the data before feeding the data to the model and check how the normalization change your accuracy\n"
      ],
      "metadata": {
        "id": "UJYHWceA0cEV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing packages for Normalization\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "HBvLdR7J0dYd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n",
        "\n",
        "sc = StandardScaler() #Create Model\n",
        "X_train = sc.fit_transform(X_train) #Fit to data, then transform it.\n",
        "X_test = sc.transform(X_test) # Perform standardization by centering and scaling\n",
        "\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n",
        "print(my_first_nn.summary()) #Summary\n",
        "print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbpiK3630gAZ",
        "outputId": "19444073-8f8d-48f2-c9cb-fbfe9697e1e8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_13 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 641 (2.50 KB)\n",
            "Trainable params: 641 (2.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1355 - acc: 0.9720\n",
            "[0.135470449924469, 0.9720279574394226]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2\n"
      ],
      "metadata": {
        "id": "80Ww2pO-0mEK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "#scale data\n",
        "train_data /=255.0\n",
        "test_data /=255.0\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcpnRNdm0s5m",
        "outputId": "6daebcab-7ba4-4aaf-8bbb-d01e48c8b8f4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Plot the loss and accuracy for both training data and validation data using the history object in the source code.\n"
      ],
      "metadata": {
        "id": "C46jjXZF0wbG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOcfy5kD0zIh",
        "outputId": "671c5f4c-132e-430e-faeb-56ec1ea32cfb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 6s 23ms/step - loss: 0.2971 - accuracy: 0.9094 - val_loss: 0.1979 - val_accuracy: 0.9350\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.1020 - accuracy: 0.9689 - val_loss: 0.0786 - val_accuracy: 0.9756\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 7s 29ms/step - loss: 0.0626 - accuracy: 0.9807 - val_loss: 0.0711 - val_accuracy: 0.9778\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 0.1107 - val_accuracy: 0.9689\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.0323 - accuracy: 0.9899 - val_loss: 0.0607 - val_accuracy: 0.9818\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.0222 - accuracy: 0.9935 - val_loss: 0.0626 - val_accuracy: 0.9820\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0650 - val_accuracy: 0.9812\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0588 - val_accuracy: 0.9840\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.1221 - val_accuracy: 0.9709\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 7s 28ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0720 - val_accuracy: 0.9822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[test_loss, test_acc] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))\n",
        "\n",
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAOTlCoQ09yt",
        "outputId": "ee96ada2-52e2-4ca0-a11b-8eedff8ed664"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0720 - accuracy: 0.9822\n",
            "Evaluation result on Test Data : Loss = 0.07197161018848419, accuracy = 0.982200026512146\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accuracy', 'val_accuracy','loss','val_loss'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "qRHXdBD41Ktv",
        "outputId": "fa82bf33-c575-4d6b-e456-83b87f3ef15a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Plot one of the images in the test data, and then do inferencing to check what is the prediction of the model on that single image.\n"
      ],
      "metadata": {
        "id": "QByYKqFp1OM-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_data[0].reshape(28,28))\n",
        "print(\"predicted label:\",model.predict(test_data[0].reshape(1,784)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "SnELZIB61YGi",
        "outputId": "01307acd-0630-4efc-e992-5dfaf92bcc59"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 188ms/step\n",
            "predicted label: [[6.8648305e-08 2.3208010e-07 1.0546088e-06 4.0319173e-06 2.1566616e-07\n",
            "  1.8492012e-09 1.1381716e-13 9.9999130e-01 5.8084937e-09 3.1302025e-06]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbKUlEQVR4nO3df3DU9b3v8dcCyQqYbAwh2UQCBvxBFUinFNJclMaSS4hnGFDOHVBvBxwvXGlwhNTqiaMgbeemxTno0UPxnxbqGQHLuQJHTi8djSaMbYKHKIfLtWZIJhYYklBzD9kQJATyuX9wXV1JwO+ym3eyPB8z3xmy+/3k+/br6pNvsvnG55xzAgBggA2zHgAAcH0iQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwMQI6wG+rre3VydPnlRKSop8Pp/1OAAAj5xz6uzsVE5OjoYN6/86Z9AF6OTJk8rNzbUeAwBwjY4fP65x48b1+/ygC1BKSook6W7dpxFKMp4GAODVBfXoff0+/P/z/sQtQJs2bdILL7yg1tZW5efn65VXXtHMmTOvuu6LL7uNUJJG+AgQAAw5//8Oo1f7Nkpc3oTwxhtvqLy8XOvWrdOHH36o/Px8lZSU6NSpU/E4HABgCIpLgDZu3Kjly5frkUce0Z133qlXX31Vo0aN0m9+85t4HA4AMATFPEDnz59XfX29iouLvzzIsGEqLi5WbW3tZft3d3crFApFbACAxBfzAH322We6ePGisrKyIh7PyspSa2vrZftXVlYqEAiEN94BBwDXB/MfRK2oqFBHR0d4O378uPVIAIABEPN3wWVkZGj48OFqa2uLeLytrU3BYPCy/f1+v/x+f6zHAAAMcjG/AkpOTtb06dNVVVUVfqy3t1dVVVUqLCyM9eEAAENUXH4OqLy8XEuXLtV3v/tdzZw5Uy+99JK6urr0yCOPxONwAIAhKC4BWrx4sf76179q7dq1am1t1be//W3t27fvsjcmAACuXz7nnLMe4qtCoZACgYCKtIA7IQDAEHTB9ahae9TR0aHU1NR+9zN/FxwA4PpEgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMxDxAzz//vHw+X8Q2efLkWB8GADDEjYjHJ73rrrv0zjvvfHmQEXE5DABgCItLGUaMGKFgMBiPTw0ASBBx+R7Q0aNHlZOTo4kTJ+rhhx/WsWPH+t23u7tboVAoYgMAJL6YB6igoEBbt27Vvn37tHnzZjU3N+uee+5RZ2dnn/tXVlYqEAiEt9zc3FiPBAAYhHzOORfPA5w+fVoTJkzQxo0b9eijj172fHd3t7q7u8Mfh0Ih5ebmqkgLNMKXFM/RAABxcMH1qFp71NHRodTU1H73i/u7A9LS0nT77bersbGxz+f9fr/8fn+8xwAADDJx/zmgM2fOqKmpSdnZ2fE+FABgCIl5gJ588knV1NTo008/1Z/+9Cfdf//9Gj58uB588MFYHwoAMITF/EtwJ06c0IMPPqj29naNHTtWd999t+rq6jR27NhYHwoAMITFPEA7duyI9acEACQg7gUHADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJiI+y+kw8BqX17oec34H/b9ywKv5pNTWZ7XnO/2/ltub97ufc2oE2c8r5Gk3kMfR7UOgHdcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEd8NOME/9ZJvnNYtG/0d0B5sU3TLPirwv+fTC2agO9Q9/vTeqdRg4H5ya4HnN6L8PRHWsEVX1Ua3DN8MVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRJpiXn1niec3aadH9PeSmPzvPa/7jWz7Pa5Knnfa8ZsOUNz2vkaQXsw94XvOvZ2/0vOZvRp3xvGYgfe7Oe15zoHu05zVFN/R4XqMo/h3duvi/ez+OpNurolqGb4grIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjTTCj/9n7jRpH/3McBulH6gAd55VgUVTrfj7rFs9rUmsaPa/ZUHSr5zUDacTnvZ7XjD7c4nnNmP3/0/OaqclJnteM+tT7GsQfV0AAABMECABgwnOA9u/fr/nz5ysnJ0c+n0+7d++OeN45p7Vr1yo7O1sjR45UcXGxjh49Gqt5AQAJwnOAurq6lJ+fr02bNvX5/IYNG/Tyyy/r1Vdf1YEDBzR69GiVlJTo3Llz1zwsACBxeH4TQmlpqUpLS/t8zjmnl156Sc8++6wWLFggSXrttdeUlZWl3bt3a8kS77+tEwCQmGL6PaDm5ma1traquLg4/FggEFBBQYFqa2v7XNPd3a1QKBSxAQASX0wD1NraKknKysqKeDwrKyv83NdVVlYqEAiEt9zc3FiOBAAYpMzfBVdRUaGOjo7wdvz4ceuRAAADIKYBCgaDkqS2traIx9va2sLPfZ3f71dqamrEBgBIfDENUF5enoLBoKqqqsKPhUIhHThwQIWFhbE8FABgiPP8LrgzZ86osfHLW480Nzfr0KFDSk9P1/jx47V69Wr9/Oc/12233aa8vDw999xzysnJ0cKFC2M5NwBgiPMcoIMHD+ree+8Nf1xeXi5JWrp0qbZu3aqnnnpKXV1dWrFihU6fPq27775b+/bt0w033BC7qQEAQ57POeesh/iqUCikQCCgIi3QCB83EASGivb/5v3L7LXr/9Hzmo3/d7LnNfvnTvK8RpIutPT97l1c2QXXo2rtUUdHxxW/r2/+LjgAwPWJAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJjz/OgYAiW/EhFzPa/7xGe93tk7yDfe8Zuc/FHteM6al1vMaxB9XQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GCuAyn6y52fOaGX6f5zX/5/znntekf3zW8xoMTlwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpkMC6/2ZGVOs+/NsXo1jl97xi5RNPeF4z8k8feF6DwYkrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjBRLYsdLo/o55o8/7jUUfbP7PnteM2vfvntc4zyswWHEFBAAwQYAAACY8B2j//v2aP3++cnJy5PP5tHv37ojnly1bJp/PF7HNmzcvVvMCABKE5wB1dXUpPz9fmzZt6nefefPmqaWlJbxt3779moYEACQez29CKC0tVWlp6RX38fv9CgaDUQ8FAEh8cfkeUHV1tTIzM3XHHXdo5cqVam9v73ff7u5uhUKhiA0AkPhiHqB58+bptddeU1VVlX75y1+qpqZGpaWlunjxYp/7V1ZWKhAIhLfc3NxYjwQAGIRi/nNAS5YsCf956tSpmjZtmiZNmqTq6mrNmTPnsv0rKipUXl4e/jgUChEhALgOxP1t2BMnTlRGRoYaGxv7fN7v9ys1NTViAwAkvrgH6MSJE2pvb1d2dna8DwUAGEI8fwnuzJkzEVczzc3NOnTokNLT05Wenq7169dr0aJFCgaDampq0lNPPaVbb71VJSUlMR0cADC0eQ7QwYMHde+994Y//uL7N0uXLtXmzZt1+PBh/fa3v9Xp06eVk5OjuXPn6mc/+5n8fu/3lgIAJC7PASoqKpJz/d8O8A9/+MM1DQSgb8NSUjyv+eE970d1rFDvOc9rTv2PiZ7X+Lv/zfMaJA7uBQcAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATMf+V3ADi4+jzd3leszfjV1Eda8HRRZ7X+H/Pna3hDVdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkYKGOj4r9/zvObw4pc9r2m60ON5jSSd+eU4z2v8aonqWLh+cQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqTANRpxc47nNaufe8PzGr/P+3+uS/79h57XSNLY//VvUa0DvOAKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1Iga/wjfD+n0T+3hOe1/yXG9s9r3m9M9Pzmqznovs7Zm9UqwBvuAICAJggQAAAE54CVFlZqRkzZiglJUWZmZlauHChGhoaIvY5d+6cysrKNGbMGN14441atGiR2traYjo0AGDo8xSgmpoalZWVqa6uTm+//bZ6eno0d+5cdXV1hfdZs2aN3nrrLe3cuVM1NTU6efKkHnjggZgPDgAY2jx9x3Xfvn0RH2/dulWZmZmqr6/X7Nmz1dHRoV//+tfatm2bfvCDH0iStmzZom9961uqq6vT9773vdhNDgAY0q7pe0AdHR2SpPT0dElSfX29enp6VFxcHN5n8uTJGj9+vGpra/v8HN3d3QqFQhEbACDxRR2g3t5erV69WrNmzdKUKVMkSa2trUpOTlZaWlrEvllZWWptbe3z81RWVioQCIS33NzcaEcCAAwhUQeorKxMR44c0Y4dO65pgIqKCnV0dIS348ePX9PnAwAMDVH9IOqqVau0d+9e7d+/X+PGjQs/HgwGdf78eZ0+fTriKqitrU3BYLDPz+X3++X3+6MZAwAwhHm6AnLOadWqVdq1a5feffdd5eXlRTw/ffp0JSUlqaqqKvxYQ0ODjh07psLCwthMDABICJ6ugMrKyrRt2zbt2bNHKSkp4e/rBAIBjRw5UoFAQI8++qjKy8uVnp6u1NRUPf744yosLOQdcACACJ4CtHnzZklSUVFRxONbtmzRsmXLJEkvvviihg0bpkWLFqm7u1slJSX61a9+FZNhAQCJw+ecc9ZDfFUoFFIgEFCRFmiEL8l6HFxnfNPv8rzmX//ln+IwyeX+U0WZ5zVpr/X94w9APF1wParWHnV0dCg1NbXf/bgXHADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExE9RtRgcFu+J23R7VuxY49MZ6kb3f+xvudrW/5p7o4TALY4QoIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBzUiRkD750U1RrZs/KhTjSfo2rvq890XOxX4QwBBXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GikHv3PyZntdUzf/7KI82Ksp1ALziCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSDHonZw13POa8SMG7qair3dmel6TFDrveY3zvAIY3LgCAgCYIEAAABOeAlRZWakZM2YoJSVFmZmZWrhwoRoaGiL2KSoqks/ni9gee+yxmA4NABj6PAWopqZGZWVlqqur09tvv62enh7NnTtXXV1dEfstX75cLS0t4W3Dhg0xHRoAMPR5ehPCvn37Ij7eunWrMjMzVV9fr9mzZ4cfHzVqlILBYGwmBAAkpGv6HlBHR4ckKT09PeLx119/XRkZGZoyZYoqKip09uzZfj9Hd3e3QqFQxAYASHxRvw27t7dXq1ev1qxZszRlypTw4w899JAmTJignJwcHT58WE8//bQaGhr05ptv9vl5KisrtX79+mjHAAAMUVEHqKysTEeOHNH7778f8fiKFSvCf546daqys7M1Z84cNTU1adKkSZd9noqKCpWXl4c/DoVCys3NjXYsAMAQEVWAVq1apb1792r//v0aN27cFfctKCiQJDU2NvYZIL/fL7/fH80YAIAhzFOAnHN6/PHHtWvXLlVXVysvL++qaw4dOiRJys7OjmpAAEBi8hSgsrIybdu2TXv27FFKSopaW1slSYFAQCNHjlRTU5O2bdum++67T2PGjNHhw4e1Zs0azZ49W9OmTYvLPwAAYGjyFKDNmzdLuvTDpl+1ZcsWLVu2TMnJyXrnnXf00ksvqaurS7m5uVq0aJGeffbZmA0MAEgMnr8EdyW5ubmqqam5poEAANcH7oYNfEVl+52e19SW3OJ5jWv5357XAImGm5ECAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GSkGvYl/V+t5zX1/9504TNKf1gE8FpA4uAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgYtDdC845J0m6oB7JGQ8DAPDsgnokffn/8/4MugB1dnZKkt7X740nAQBci87OTgUCgX6f97mrJWqA9fb26uTJk0pJSZHP54t4LhQKKTc3V8ePH1dqaqrRhPY4D5dwHi7hPFzCebhkMJwH55w6OzuVk5OjYcP6/07PoLsCGjZsmMaNG3fFfVJTU6/rF9gXOA+XcB4u4Txcwnm4xPo8XOnK5wu8CQEAYIIAAQBMDKkA+f1+rVu3Tn6/33oUU5yHSzgPl3AeLuE8XDKUzsOgexMCAOD6MKSugAAAiYMAAQBMECAAgAkCBAAwMWQCtGnTJt1yyy264YYbVFBQoA8++MB6pAH3/PPPy+fzRWyTJ0+2Hivu9u/fr/nz5ysnJ0c+n0+7d++OeN45p7Vr1yo7O1sjR45UcXGxjh49ajNsHF3tPCxbtuyy18e8efNsho2TyspKzZgxQykpKcrMzNTChQvV0NAQsc+5c+dUVlamMWPG6MYbb9SiRYvU1tZmNHF8fJPzUFRUdNnr4bHHHjOauG9DIkBvvPGGysvLtW7dOn344YfKz89XSUmJTp06ZT3agLvrrrvU0tIS3t5//33rkeKuq6tL+fn52rRpU5/Pb9iwQS+//LJeffVVHThwQKNHj1ZJSYnOnTs3wJPG19XOgyTNmzcv4vWxffv2AZww/mpqalRWVqa6ujq9/fbb6unp0dy5c9XV1RXeZ82aNXrrrbe0c+dO1dTU6OTJk3rggQcMp469b3IeJGn58uURr4cNGzYYTdwPNwTMnDnTlZWVhT++ePGiy8nJcZWVlYZTDbx169a5/Px86zFMSXK7du0Kf9zb2+uCwaB74YUXwo+dPn3a+f1+t337doMJB8bXz4Nzzi1dutQtWLDAZB4rp06dcpJcTU2Nc+7Sv/ukpCS3c+fO8D5//vOfnSRXW1trNWbcff08OOfc97//fffEE0/YDfUNDPoroPPnz6u+vl7FxcXhx4YNG6bi4mLV1tYaTmbj6NGjysnJ0cSJE/Xwww/r2LFj1iOZam5uVmtra8TrIxAIqKCg4Lp8fVRXVyszM1N33HGHVq5cqfb2duuR4qqjo0OSlJ6eLkmqr69XT09PxOth8uTJGj9+fEK/Hr5+Hr7w+uuvKyMjQ1OmTFFFRYXOnj1rMV6/Bt3NSL/us88+08WLF5WVlRXxeFZWlj755BOjqWwUFBRo69atuuOOO9TS0qL169frnnvu0ZEjR5SSkmI9nonW1lZJ6vP18cVz14t58+bpgQceUF5enpqamvTMM8+otLRUtbW1Gj58uPV4Mdfb26vVq1dr1qxZmjJliqRLr4fk5GSlpaVF7JvIr4e+zoMkPfTQQ5owYYJycnJ0+PBhPf3002poaNCbb75pOG2kQR8gfKm0tDT852nTpqmgoEATJkzQ7373Oz366KOGk2EwWLJkSfjPU6dO1bRp0zRp0iRVV1drzpw5hpPFR1lZmY4cOXJdfB/0Svo7DytWrAj/eerUqcrOztacOXPU1NSkSZMmDfSYfRr0X4LLyMjQ8OHDL3sXS1tbm4LBoNFUg0NaWppuv/12NTY2Wo9i5ovXAK+Py02cOFEZGRkJ+fpYtWqV9u7dq/feey/i17cEg0GdP39ep0+fjtg/UV8P/Z2HvhQUFEjSoHo9DPoAJScna/r06aqqqgo/1tvbq6qqKhUWFhpOZu/MmTNqampSdna29Shm8vLyFAwGI14foVBIBw4cuO5fHydOnFB7e3tCvT6cc1q1apV27dqld999V3l5eRHPT58+XUlJSRGvh4aGBh07diyhXg9XOw99OXTokCQNrteD9bsgvokdO3Y4v9/vtm7d6j7++GO3YsUKl5aW5lpbW61HG1A//vGPXXV1tWtubnZ//OMfXXFxscvIyHCnTp2yHi2uOjs73UcffeQ++ugjJ8lt3LjRffTRR+4vf/mLc865X/ziFy4tLc3t2bPHHT582C1YsMDl5eW5zz//3Hjy2LrSeejs7HRPPvmkq62tdc3Nze6dd95x3/nOd9xtt93mzp07Zz16zKxcudIFAgFXXV3tWlpawtvZs2fD+zz22GNu/Pjx7t1333UHDx50hYWFrrCw0HDq2LvaeWhsbHQ//elP3cGDB11zc7Pbs2ePmzhxops9e7bx5JGGRICcc+6VV15x48ePd8nJyW7mzJmurq7OeqQBt3jxYpedne2Sk5PdzTff7BYvXuwaGxutx4q79957z0m6bFu6dKlz7tJbsZ977jmXlZXl/H6/mzNnjmtoaLAdOg6udB7Onj3r5s6d68aOHeuSkpLchAkT3PLlyxPuL2l9/fNLclu2bAnv8/nnn7sf/ehH7qabbnKjRo1y999/v2tpabEbOg6udh6OHTvmZs+e7dLT053f73e33nqr+8lPfuI6OjpsB/8afh0DAMDEoP8eEAAgMREgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJv4fx1BnJzDsp98AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question3. We had used 2 hidden layers and Relu activation. Try to change the number of hidden layer and the activation to tanh or sigmoid and see what happens.\n"
      ],
      "metadata": {
        "id": "gnM13FRI1cRt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#increasing the number of hidden layers to 6\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))\n",
        "\n",
        "[test_loss1, test_acc1] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data with 4 hidden layers: Loss = {}, accuracy = {}\".format(test_loss1, test_acc1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON8rwt6I1fql",
        "outputId": "f66942b6-339c-48dc-d041-c5e9c8cf105c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 23s 89ms/step - loss: 0.4681 - accuracy: 0.8530 - val_loss: 0.1919 - val_accuracy: 0.9448\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 28s 119ms/step - loss: 0.1279 - accuracy: 0.9632 - val_loss: 0.1270 - val_accuracy: 0.9645\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 16s 67ms/step - loss: 0.0793 - accuracy: 0.9763 - val_loss: 0.0787 - val_accuracy: 0.9767\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 16s 68ms/step - loss: 0.0577 - accuracy: 0.9829 - val_loss: 0.0898 - val_accuracy: 0.9777\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 15s 65ms/step - loss: 0.0421 - accuracy: 0.9880 - val_loss: 0.0897 - val_accuracy: 0.9752\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 16s 67ms/step - loss: 0.0328 - accuracy: 0.9901 - val_loss: 0.0850 - val_accuracy: 0.9796\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 17s 71ms/step - loss: 0.0266 - accuracy: 0.9919 - val_loss: 0.1249 - val_accuracy: 0.9701\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 16s 67ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.0864 - val_accuracy: 0.9811\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 16s 67ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.0778 - val_accuracy: 0.9829\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 16s 66ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.0900 - val_accuracy: 0.9821\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0900 - accuracy: 0.9821\n",
            "Evaluation result on Test Data with 4 hidden layers: Loss = 0.09003212302923203, accuracy = 0.9821000099182129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#All hidden layers with tanh activation\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='tanh', input_shape=(dimData,)))\n",
        "model.add(Dense(612, activation='tanh'))\n",
        "model.add(Dense(712, activation='tanh'))\n",
        "model.add(Dense(812, activation='tanh'))\n",
        "model.add(Dense(712, activation='tanh'))\n",
        "model.add(Dense(812, activation='tanh'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))\n",
        "\n",
        "[test_loss2, test_acc2] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data with tanh activation: Loss = {}, accuracy = {}\".format(test_loss2, test_acc2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J38tHxt01oAZ",
        "outputId": "ce26615a-5d3a-4e93-fa09-53e3948ec61c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 30s 124ms/step - loss: 0.9565 - accuracy: 0.7810 - val_loss: 0.4018 - val_accuracy: 0.8891\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 35s 150ms/step - loss: 0.2414 - accuracy: 0.9303 - val_loss: 0.2155 - val_accuracy: 0.9354\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 25s 107ms/step - loss: 0.1629 - accuracy: 0.9517 - val_loss: 0.1969 - val_accuracy: 0.9454\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 25s 108ms/step - loss: 0.1189 - accuracy: 0.9648 - val_loss: 0.1538 - val_accuracy: 0.9591\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 26s 113ms/step - loss: 0.0917 - accuracy: 0.9725 - val_loss: 0.2042 - val_accuracy: 0.9440\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 28s 118ms/step - loss: 0.0730 - accuracy: 0.9778 - val_loss: 0.1968 - val_accuracy: 0.9495\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 24s 103ms/step - loss: 0.0586 - accuracy: 0.9810 - val_loss: 0.2932 - val_accuracy: 0.9287\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 26s 112ms/step - loss: 0.0485 - accuracy: 0.9845 - val_loss: 0.1790 - val_accuracy: 0.9537\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 26s 111ms/step - loss: 0.0371 - accuracy: 0.9881 - val_loss: 0.1077 - val_accuracy: 0.9749\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 25s 106ms/step - loss: 0.0332 - accuracy: 0.9896 - val_loss: 0.1049 - val_accuracy: 0.9735\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1049 - accuracy: 0.9735\n",
            "Evaluation result on Test Data with tanh activation: Loss = 0.10486921668052673, accuracy = 0.9735000133514404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the same code without scaling the images and check the performance?\n",
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "# print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))\n",
        "\n",
        "[test_loss3, test_acc3] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data without scaling: Loss = {}, accuracy = {}\".format(test_loss3, test_acc3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abrnh30K-skQ",
        "outputId": "74f6690c-fc16-4608-ac94-f856100add32"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 7s 24ms/step - loss: 6.9328 - accuracy: 0.8734 - val_loss: 0.9606 - val_accuracy: 0.9037\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.4330 - accuracy: 0.9456 - val_loss: 0.5084 - val_accuracy: 0.9279\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.2530 - accuracy: 0.9593 - val_loss: 0.2741 - val_accuracy: 0.9587\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.1957 - accuracy: 0.9675 - val_loss: 0.2855 - val_accuracy: 0.9609\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.1681 - accuracy: 0.9724 - val_loss: 0.2929 - val_accuracy: 0.9642\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.1476 - accuracy: 0.9767 - val_loss: 0.3955 - val_accuracy: 0.9602\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.1246 - accuracy: 0.9799 - val_loss: 0.3606 - val_accuracy: 0.9603\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.1224 - accuracy: 0.9813 - val_loss: 0.3287 - val_accuracy: 0.9701\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.1169 - accuracy: 0.9835 - val_loss: 0.3156 - val_accuracy: 0.9708\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 7s 29ms/step - loss: 0.1038 - accuracy: 0.9857 - val_loss: 0.4293 - val_accuracy: 0.9679\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4293 - accuracy: 0.9679\n",
            "Evaluation result on Test Data without scaling: Loss = 0.4293402433395386, accuracy = 0.9678999781608582\n"
          ]
        }
      ]
    }
  ]
}